{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39309648",
   "metadata": {},
   "source": [
    "# PDL Lab6. Text corpus creation and binary classification using DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c96dc",
   "metadata": {},
   "source": [
    "###  1. Dataset Creation: Create a dataset of 20 lines of text for class 1: motivational lines(each line considered as document) and 20 lines of text for class 2: demotivationallines. 20 lines of text per class and store them in text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6830d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus-2022\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus-2022\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7aadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Quotes.csv\",encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699670eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3f9ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every dead body on Mt. Everest was once a high...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Light travels faster than sound. This is why s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just because we accept you as you are doesn’t ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Idiocy – never underestimate the power of stup...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If life doesn’t break you today, don’t worry. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Target\n",
       "0  Every dead body on Mt. Everest was once a high...       1\n",
       "1  Light travels faster than sound. This is why s...       1\n",
       "2  Just because we accept you as you are doesn’t ...       1\n",
       "3  Idiocy – never underestimate the power of stup...       1\n",
       "4  If life doesn’t break you today, don’t worry. ...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6413aeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text\n",
       "Target      \n",
       "0         20\n",
       "1         20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71132bc0",
   "metadata": {},
   "source": [
    "### 2. Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "464b8b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Every dead body on Mt. Everest was once a high...\n",
       "1     Light travels faster than sound. This is why s...\n",
       "2     Just because we accept you as you are doesn’t ...\n",
       "3     Idiocy – never underestimate the power of stup...\n",
       "4     If life doesn’t break you today, don’t worry. ...\n",
       "5     People who say they’ll give 110% don’t underst...\n",
       "6     A thousand-mile journey starts with one step. ...\n",
       "7     If you never try anything new, you’ll miss out...\n",
       "8     Two things are infinite: the universe and huma...\n",
       "9     If at first, you don't succeed, try, try again...\n",
       "10    Today is the first day of the rest of your lif...\n",
       "11    It could be that your purpose in life is to se...\n",
       "12    Just because you are unique doesn't mean you a...\n",
       "13    Oh, you hate your job? Why didn’t you say so? ...\n",
       "14    I am free of all prejudice. I hate everyone eq...\n",
       "15    Multitasking – the art of doing twice as much ...\n",
       "16    Always remember that you are absolutely unique...\n",
       "17    The story so far: In the beginning, the Univer...\n",
       "18    Life is pain. Anyone who says otherwise is sel...\n",
       "19    Everything happens for a reason. Sometimes the...\n",
       "20       Doubt kills more dreams than failure ever will\n",
       "21    Keep your face always toward the sunshine, and...\n",
       "22    Whether you think you can or think you can’t, ...\n",
       "23    Your talent determines what you can do. Your m...\n",
       "24          You do not find the happy life. You make it\n",
       "25    You’ve gotta dance like there’s nobody watchin...\n",
       "26    Happiness is not something readymade. It comes...\n",
       "27    Folks are usually about as happy as they make ...\n",
       "28    It is during our darkest moments that we must ...\n",
       "29    Develop success from failures. Discouragement ...\n",
       "30    You learn more from failure than from success....\n",
       "31    Fairytales do not tell children that dragons e...\n",
       "32    The bad news is time flies. The good news is y...\n",
       "33    Just because it’s what’s done doesn’t mean it’...\n",
       "34    With a smile and a song, life is just like a b...\n",
       "35    It’s no use going back to yesterday because I ...\n",
       "36    When we get to the end of the story, you will ...\n",
       "37    The most important thing in life is to stop sa...\n",
       "38    Learn as if you will live forever, live like y...\n",
       "39    Life isn’t about finding yourself. Life is abo...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62d7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['Text']\n",
    "y=df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bc3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0560f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "\n",
    "    tokens = review.lower().split()\n",
    "    filtered_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5bb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Asus-2022\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8de8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=X.tolist()\n",
    "fax=[]\n",
    "for i in temp:\n",
    "    fax.append(clean_review(i))\n",
    "n_X=pd.Series(fax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a934e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>110</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>action</th>\n",
       "      <th>adam</th>\n",
       "      <th>again</th>\n",
       "      <th>already</th>\n",
       "      <th>always</th>\n",
       "      <th>angry</th>\n",
       "      <th>...</th>\n",
       "      <th>whether</th>\n",
       "      <th>widely</th>\n",
       "      <th>will</th>\n",
       "      <th>willing</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>worry</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>you</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219023</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.341752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.275951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211986</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317470</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.26824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.26824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.26824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313992</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218568</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351872</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220233</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456033</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205884</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200327</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.251697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         110  abandoned  absolutely    accept    action     adam     again  \\\n",
       "0   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "2   0.000000   0.349938    0.000000  0.349938  0.000000  0.00000  0.000000   \n",
       "3   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "5   0.341752   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "6   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.275951   \n",
       "7   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "8   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "9   0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.288800   \n",
       "10  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "11  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "12  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "13  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "14  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "15  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "16  0.000000   0.000000    0.353079  0.000000  0.000000  0.00000  0.000000   \n",
       "17  0.000000   0.000000    0.000000  0.000000  0.000000  0.26824  0.000000   \n",
       "18  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "19  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "20  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "21  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "22  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "23  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "24  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "25  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "26  0.000000   0.000000    0.000000  0.000000  0.456033  0.00000  0.000000   \n",
       "27  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "28  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "29  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "30  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "31  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "32  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "33  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "34  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "35  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "36  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "37  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "38  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "39  0.000000   0.000000    0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "     already    always    angry  ...   whether   widely      will   willing  \\\n",
       "0   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "13  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "16  0.000000  0.317470  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.26824  ...  0.000000  0.26824  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "21  0.000000  0.313992  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.00000  ...  0.351872  0.00000  0.000000  0.000000   \n",
       "23  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.230112   \n",
       "24  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "25  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "26  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "27  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "28  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "29  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "30  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "31  0.174585  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "32  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "33  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "34  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "35  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "36  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "37  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.251697  0.000000   \n",
       "38  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "39  0.000000  0.000000  0.00000  ...  0.000000  0.00000  0.000000  0.000000   \n",
       "\n",
       "        wish      work     worry  yesterday       you  yourself  \n",
       "0   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000   0.000000  0.219023  0.000000  \n",
       "3   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000000  0.407188   0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.341752  0.000000   0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000   0.000000  0.211986  0.000000  \n",
       "8   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000   0.326295  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "15  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "16  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "19  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "20  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "21  0.000000  0.000000  0.000000   0.000000  0.218568  0.000000  \n",
       "22  0.000000  0.000000  0.000000   0.000000  0.220233  0.000000  \n",
       "23  0.000000  0.000000  0.000000   0.000000  0.144025  0.000000  \n",
       "24  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "25  0.000000  0.000000  0.000000   0.000000  0.225684  0.000000  \n",
       "26  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "27  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "28  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "29  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "30  0.000000  0.000000  0.000000   0.000000  0.205884  0.000000  \n",
       "31  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "32  0.000000  0.000000  0.000000   0.000000  0.200327  0.000000  \n",
       "33  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "34  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "35  0.000000  0.000000  0.000000   0.340979  0.000000  0.000000  \n",
       "36  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "37  0.251697  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "38  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  \n",
       "39  0.000000  0.000000  0.000000   0.000000  0.000000  0.428806  \n",
       "\n",
       "[40 rows x 255 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "vectors = tfidf.fit_transform(n_X)\n",
    "features_name = tfidf.get_feature_names()\n",
    "text_vect = pd.DataFrame(vectors.todense(),columns=features_name)\n",
    "text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c939bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp = tf.Variable(text_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14d382",
   "metadata": {},
   "source": [
    "### 3. Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db8c60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(text_vect,y,train_size=0.75,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f4830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 255)\n",
      "(30,)\n",
      "(10, 255)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72371e83",
   "metadata": {},
   "source": [
    "### 4. Model Creation:\n",
    "\n",
    "### 5. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0026e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0193bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               32768     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,786\n",
      "Trainable params: 43,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu',input_dim=X_train.shape[1]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid')) #output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe6126f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 2s - loss: 0.6927 - accuracy: 0.5833 - val_loss: 0.7019 - val_accuracy: 0.3333 - 2s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6849 - accuracy: 0.5833 - val_loss: 0.7032 - val_accuracy: 0.3333 - 56ms/epoch - 28ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.6788 - accuracy: 0.5833 - val_loss: 0.7057 - val_accuracy: 0.3333 - 56ms/epoch - 28ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.6718 - accuracy: 0.5833 - val_loss: 0.7094 - val_accuracy: 0.3333 - 49ms/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.6634 - accuracy: 0.5833 - val_loss: 0.7128 - val_accuracy: 0.3333 - 66ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.6545 - accuracy: 0.5833 - val_loss: 0.7171 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.6432 - accuracy: 0.5833 - val_loss: 0.7214 - val_accuracy: 0.3333 - 59ms/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.6326 - accuracy: 0.5833 - val_loss: 0.7265 - val_accuracy: 0.3333 - 59ms/epoch - 30ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.6190 - accuracy: 0.5833 - val_loss: 0.7320 - val_accuracy: 0.3333 - 63ms/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.6042 - accuracy: 0.5833 - val_loss: 0.7386 - val_accuracy: 0.3333 - 56ms/epoch - 28ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.5857 - accuracy: 0.5833 - val_loss: 0.7471 - val_accuracy: 0.3333 - 59ms/epoch - 29ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.5641 - accuracy: 0.5833 - val_loss: 0.7604 - val_accuracy: 0.3333 - 52ms/epoch - 26ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.5412 - accuracy: 0.5833 - val_loss: 0.7767 - val_accuracy: 0.3333 - 64ms/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 0.5172 - accuracy: 0.5833 - val_loss: 0.7920 - val_accuracy: 0.3333 - 67ms/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 0.4902 - accuracy: 0.6250 - val_loss: 0.8122 - val_accuracy: 0.3333 - 64ms/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 0.4581 - accuracy: 0.7917 - val_loss: 0.8409 - val_accuracy: 0.3333 - 60ms/epoch - 30ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 0.4317 - accuracy: 0.9167 - val_loss: 0.8796 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 0.3982 - accuracy: 0.9583 - val_loss: 0.9198 - val_accuracy: 0.3333 - 57ms/epoch - 29ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 0.3690 - accuracy: 1.0000 - val_loss: 0.9703 - val_accuracy: 0.3333 - 57ms/epoch - 28ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 0.3406 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.3333 - 50ms/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 0.3158 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.3333 - 59ms/epoch - 30ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 0.2932 - accuracy: 1.0000 - val_loss: 1.1580 - val_accuracy: 0.3333 - 66ms/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 0.2729 - accuracy: 1.0000 - val_loss: 1.2147 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 0.2553 - accuracy: 1.0000 - val_loss: 1.2663 - val_accuracy: 0.3333 - 66ms/epoch - 33ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 0.2385 - accuracy: 1.0000 - val_loss: 1.3160 - val_accuracy: 0.3333 - 65ms/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.3333 - 57ms/epoch - 29ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.4030 - val_accuracy: 0.3333 - 59ms/epoch - 29ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.3333 - 59ms/epoch - 29ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 0.1692 - accuracy: 1.0000 - val_loss: 1.3718 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 0.1488 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.3333 - 48ms/epoch - 24ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 0.1272 - accuracy: 1.0000 - val_loss: 1.2657 - val_accuracy: 0.3333 - 54ms/epoch - 27ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 0.1043 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.3333 - 55ms/epoch - 27ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 0.0854 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.3333 - 59ms/epoch - 30ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 0.0651 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.3333 - 49ms/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.3333 - 56ms/epoch - 28ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.6667 - 44ms/epoch - 22ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.7213 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.6526 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.8333 - 61ms/epoch - 31ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5785 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 8.8775e-04 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 7.4291e-04 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 6.4013e-04 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 5.6918e-04 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.8333 - 63ms/epoch - 31ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 5.0245e-04 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 4.5746e-04 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 4.2557e-04 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8333 - 59ms/epoch - 30ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 3.9200e-04 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 3.6565e-04 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.8333 - 61ms/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 3.4293e-04 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.8333 - 65ms/epoch - 33ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 3.2530e-04 - accuracy: 1.0000 - val_loss: 0.6592 - val_accuracy: 0.8333 - 61ms/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 3.0771e-04 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 2.9409e-04 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 2.8089e-04 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8333 - 78ms/epoch - 39ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 2.6909e-04 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 2.5919e-04 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 2.4905e-04 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 2.4080e-04 - accuracy: 1.0000 - val_loss: 0.6673 - val_accuracy: 0.8333 - 68ms/epoch - 34ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 2.3326e-04 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 2.2574e-04 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 2.1935e-04 - accuracy: 1.0000 - val_loss: 0.6692 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 2.1200e-04 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 2.0613e-04 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 2.0089e-04 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 1.9488e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 1.8991e-04 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8333 - 66ms/epoch - 33ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 1.8551e-04 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 1.8017e-04 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8333 - 49ms/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 1.7607e-04 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 1.7175e-04 - accuracy: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8333 - 66ms/epoch - 33ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 1.6767e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 1.6352e-04 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8333 - 65ms/epoch - 33ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 1.6001e-04 - accuracy: 1.0000 - val_loss: 0.6703 - val_accuracy: 0.8333 - 64ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 1.5636e-04 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 1.5248e-04 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 1.4962e-04 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 1.4615e-04 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 1.4318e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 1.3966e-04 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8333 - 65ms/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 1.3702e-04 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8333 - 64ms/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 1.3390e-04 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8333 - 63ms/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 1.3149e-04 - accuracy: 1.0000 - val_loss: 0.6739 - val_accuracy: 0.8333 - 59ms/epoch - 30ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 1.2845e-04 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8333 - 51ms/epoch - 25ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 1.2335e-04 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 0.6738 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 1.1761e-04 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 1.1543e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 1.1299e-04 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 1.1045e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 1.0833e-04 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 1.0610e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32fc84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9918 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9917682409286499, 0.6000000238418579]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36534bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bb680",
   "metadata": {},
   "source": [
    "#### Model with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25a6d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(512, activation='relu',input_dim=X_train.shape[1]))\n",
    "model2.add(Dense(256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53de288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               131072    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303,682\n",
      "Trainable params: 303,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(2, activation='sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd7d668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 2s - loss: 0.6944 - accuracy: 0.5833 - val_loss: 0.7036 - val_accuracy: 0.3333 - 2s/epoch - 883ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6541 - accuracy: 0.6667 - val_loss: 0.7132 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.6170 - accuracy: 0.7500 - val_loss: 0.7324 - val_accuracy: 0.3333 - 65ms/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.5664 - accuracy: 0.8333 - val_loss: 0.7565 - val_accuracy: 0.3333 - 63ms/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.5001 - accuracy: 0.9167 - val_loss: 0.7830 - val_accuracy: 0.3333 - 63ms/epoch - 31ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.4194 - accuracy: 0.9583 - val_loss: 0.8234 - val_accuracy: 0.3333 - 67ms/epoch - 34ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.3294 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.3333 - 58ms/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.2401 - accuracy: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.3333 - 57ms/epoch - 29ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.1567 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.5000 - 52ms/epoch - 26ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.8912 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.6667 - 67ms/epoch - 34ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.6667 - 57ms/epoch - 28ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.5000 - 61ms/epoch - 30ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 4.7820e-04 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.5000 - 62ms/epoch - 31ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 2.0404e-04 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 0.6667 - 57ms/epoch - 29ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 1.0880e-04 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.6667 - 56ms/epoch - 28ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 6.4840e-05 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.6667 - 63ms/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 4.0872e-05 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.5000 - 67ms/epoch - 33ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 2.6891e-05 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 2.0131e-05 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.5000 - 57ms/epoch - 29ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 1.5740e-05 - accuracy: 1.0000 - val_loss: 0.6961 - val_accuracy: 0.5000 - 66ms/epoch - 33ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 1.2487e-05 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.5000 - 65ms/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 9.8694e-06 - accuracy: 1.0000 - val_loss: 0.7126 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 8.5581e-06 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.5000 - 56ms/epoch - 28ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 7.2916e-06 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 6.4074e-06 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.5000 - 61ms/epoch - 30ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 5.7270e-06 - accuracy: 1.0000 - val_loss: 0.7315 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 5.0564e-06 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.5000 - 66ms/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 4.7336e-06 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.5000 - 66ms/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 4.3859e-06 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.5000 - 46ms/epoch - 23ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 4.0879e-06 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.5000 - 52ms/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 3.8445e-06 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.5000 - 55ms/epoch - 27ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 3.6160e-06 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.5000 - 56ms/epoch - 28ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 3.4670e-06 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.5000 - 49ms/epoch - 24ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 3.3080e-06 - accuracy: 1.0000 - val_loss: 0.7398 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 3.1839e-06 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 3.0498e-06 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.5000 - 59ms/epoch - 30ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 2.9653e-06 - accuracy: 1.0000 - val_loss: 0.7393 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 2.8560e-06 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.5000 - 65ms/epoch - 33ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 2.7766e-06 - accuracy: 1.0000 - val_loss: 0.7386 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 2.6921e-06 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.5000 - 57ms/epoch - 29ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 2.6226e-06 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 2.5680e-06 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 2.5034e-06 - accuracy: 1.0000 - val_loss: 0.7369 - val_accuracy: 0.5000 - 68ms/epoch - 34ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 2.4438e-06 - accuracy: 1.0000 - val_loss: 0.7365 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 2.3941e-06 - accuracy: 1.0000 - val_loss: 0.7360 - val_accuracy: 0.5000 - 61ms/epoch - 31ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 2.3444e-06 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.5000 - 55ms/epoch - 27ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 2.2997e-06 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.5000 - 57ms/epoch - 29ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 2.2302e-06 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 2.1905e-06 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.5000 - 55ms/epoch - 27ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 2.1507e-06 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 2.1209e-06 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.5000 - 67ms/epoch - 33ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 2.0812e-06 - accuracy: 1.0000 - val_loss: 0.7331 - val_accuracy: 0.5000 - 57ms/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 2.0415e-06 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 2.0117e-06 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.5000 - 62ms/epoch - 31ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 1.9868e-06 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.5000 - 61ms/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 1.9471e-06 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.5000 - 62ms/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 1.9073e-06 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.5000 - 54ms/epoch - 27ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 1.8775e-06 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 1.8577e-06 - accuracy: 1.0000 - val_loss: 0.7307 - val_accuracy: 0.5000 - 67ms/epoch - 33ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 1.8229e-06 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.5000 - 61ms/epoch - 30ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 1.7881e-06 - accuracy: 1.0000 - val_loss: 0.7301 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 1.7633e-06 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.5000 - 59ms/epoch - 29ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 1.7434e-06 - accuracy: 1.0000 - val_loss: 0.7295 - val_accuracy: 0.5000 - 58ms/epoch - 29ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 1.7236e-06 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.5000 - 59ms/epoch - 29ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 1.6838e-06 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.5000 - 66ms/epoch - 33ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 1.6640e-06 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 1.6441e-06 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.5000 - 70ms/epoch - 35ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 1.6193e-06 - accuracy: 1.0000 - val_loss: 0.7283 - val_accuracy: 0.5000 - 59ms/epoch - 29ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 1.5944e-06 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.5000 - 68ms/epoch - 34ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 1.5646e-06 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.5000 - 62ms/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 1.5448e-06 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.5000 - 64ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 1.5249e-06 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.5000 - 62ms/epoch - 31ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 1.5050e-06 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 0.5000 - 72ms/epoch - 36ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 1.4951e-06 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.5000 - 59ms/epoch - 30ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 1.4702e-06 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 1.4454e-06 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.5000 - 57ms/epoch - 28ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 1.4305e-06 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.6667 - 55ms/epoch - 28ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 1.4156e-06 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.6667 - 61ms/epoch - 31ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 1.3908e-06 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.6667 - 61ms/epoch - 30ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 1.3659e-06 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.6667 - 60ms/epoch - 30ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 1.3510e-06 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 1.3411e-06 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.6667 - 59ms/epoch - 29ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 1.3361e-06 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.6667 - 65ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 1.3063e-06 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.6667 - 58ms/epoch - 29ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 1.3014e-06 - accuracy: 1.0000 - val_loss: 0.7257 - val_accuracy: 0.6667 - 71ms/epoch - 35ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 1.2865e-06 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.6667 - 62ms/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 1.2616e-06 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.6667 - 57ms/epoch - 28ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 1.2517e-06 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.6667 - 66ms/epoch - 33ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 1.2467e-06 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 1.2269e-06 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.6667 - 57ms/epoch - 28ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 1.2219e-06 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.6667 - 59ms/epoch - 29ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 1.2070e-06 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.6667 - 62ms/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 1.1971e-06 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.6667 - 62ms/epoch - 31ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 1.1822e-06 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.6667 - 59ms/epoch - 29ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 1.1722e-06 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.6667 - 59ms/epoch - 29ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 1.1623e-06 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 1.1474e-06 - accuracy: 1.0000 - val_loss: 0.7249 - val_accuracy: 0.6667 - 53ms/epoch - 26ms/step\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model2.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "772211e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step - loss: 1.2511 - accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2510502338409424, 0.30000001192092896]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b147d4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a79e06",
   "metadata": {},
   "source": [
    "#### Model with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "882f7f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 1028)              263168    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               526848    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 921,858\n",
      "Trainable params: 921,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(1028, activation='relu',input_dim=X_train.shape[1]))\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dense(2, activation='sigmoid')) #output layer\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4958265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 2s - loss: 0.6964 - accuracy: 0.4167 - val_loss: 0.7194 - val_accuracy: 0.3333 - 2s/epoch - 833ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6033 - accuracy: 0.8333 - val_loss: 0.7335 - val_accuracy: 0.3333 - 72ms/epoch - 36ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.5036 - accuracy: 1.0000 - val_loss: 0.7483 - val_accuracy: 0.3333 - 73ms/epoch - 36ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.3719 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.3333 - 69ms/epoch - 34ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.5000 - 66ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.7937 - val_accuracy: 0.5000 - 68ms/epoch - 34ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.6853 - val_accuracy: 0.5000 - 74ms/epoch - 37ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.6667 - 77ms/epoch - 39ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.6667 - 71ms/epoch - 36ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 7.3518e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 1.9981e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.8333 - 67ms/epoch - 34ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 6.3639e-05 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.8333 - 74ms/epoch - 37ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 2.3072e-05 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8333 - 71ms/epoch - 36ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 9.7155e-06 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.6667 - 72ms/epoch - 36ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 4.6541e-06 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.6667 - 79ms/epoch - 39ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 2.5034e-06 - accuracy: 1.0000 - val_loss: 0.7184 - val_accuracy: 0.6667 - 75ms/epoch - 37ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 1.5646e-06 - accuracy: 1.0000 - val_loss: 0.7662 - val_accuracy: 0.6667 - 77ms/epoch - 39ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 9.8348e-07 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.6667 - 67ms/epoch - 33ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 6.7055e-07 - accuracy: 1.0000 - val_loss: 0.8465 - val_accuracy: 0.6667 - 75ms/epoch - 38ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 5.1657e-07 - accuracy: 1.0000 - val_loss: 0.8790 - val_accuracy: 0.6667 - 84ms/epoch - 42ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 3.9736e-07 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 3.2286e-07 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.6667 - 73ms/epoch - 36ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 2.6325e-07 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 2.2848e-07 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.6667 - 62ms/epoch - 31ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 1.9372e-07 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 1.7881e-07 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 1.5895e-07 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.6667 - 69ms/epoch - 35ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 1.4901e-07 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.6667 - 65ms/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 1.4404e-07 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.6667 - 66ms/epoch - 33ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 1.3908e-07 - accuracy: 1.0000 - val_loss: 1.0235 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 1.3411e-07 - accuracy: 1.0000 - val_loss: 1.0280 - val_accuracy: 0.6667 - 77ms/epoch - 38ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 1.3411e-07 - accuracy: 1.0000 - val_loss: 1.0318 - val_accuracy: 0.6667 - 79ms/epoch - 39ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 1.2914e-07 - accuracy: 1.0000 - val_loss: 1.0348 - val_accuracy: 0.6667 - 72ms/epoch - 36ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 1.2418e-07 - accuracy: 1.0000 - val_loss: 1.0374 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 1.2418e-07 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 1.2418e-07 - accuracy: 1.0000 - val_loss: 1.0410 - val_accuracy: 0.6667 - 73ms/epoch - 36ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0424 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 1.0435 - val_accuracy: 0.6667 - 72ms/epoch - 36ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.6667 - 75ms/epoch - 37ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.6667 - 75ms/epoch - 37ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 1.1424e-07 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.6667 - 66ms/epoch - 33ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 1.0463 - val_accuracy: 0.6667 - 74ms/epoch - 37ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.6667 - 74ms/epoch - 37ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.6667 - 73ms/epoch - 36ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 1.0928e-07 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.6667 - 65ms/epoch - 33ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0469 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.6667 - 73ms/epoch - 37ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 0.6667 - 77ms/epoch - 39ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0466 - val_accuracy: 0.6667 - 76ms/epoch - 38ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.6667 - 82ms/epoch - 41ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.6667 - 76ms/epoch - 38ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0463 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0462 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.6667 - 71ms/epoch - 36ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.6667 - 74ms/epoch - 37ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0457 - val_accuracy: 0.6667 - 67ms/epoch - 34ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.6667 - 74ms/epoch - 37ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0454 - val_accuracy: 0.6667 - 79ms/epoch - 40ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0453 - val_accuracy: 0.6667 - 69ms/epoch - 34ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.6667 - 67ms/epoch - 34ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0449 - val_accuracy: 0.6667 - 67ms/epoch - 33ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.6667 - 65ms/epoch - 33ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0444 - val_accuracy: 0.6667 - 72ms/epoch - 36ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.6667 - 69ms/epoch - 35ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.6667 - 73ms/epoch - 37ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0440 - val_accuracy: 0.6667 - 75ms/epoch - 37ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.6667 - 62ms/epoch - 31ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0437 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0435 - val_accuracy: 0.6667 - 80ms/epoch - 40ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0431 - val_accuracy: 0.6667 - 73ms/epoch - 37ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0429 - val_accuracy: 0.6667 - 76ms/epoch - 38ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0428 - val_accuracy: 0.6667 - 73ms/epoch - 37ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.6667 - 68ms/epoch - 34ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.6667 - 67ms/epoch - 34ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 9.9341e-08 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.6667 - 67ms/epoch - 34ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 9.9341e-08 - accuracy: 1.0000 - val_loss: 1.0421 - val_accuracy: 0.6667 - 77ms/epoch - 39ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 9.9341e-08 - accuracy: 1.0000 - val_loss: 1.0420 - val_accuracy: 0.6667 - 72ms/epoch - 36ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0418 - val_accuracy: 0.6667 - 71ms/epoch - 35ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.6667 - 65ms/epoch - 33ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.6667 - 66ms/epoch - 33ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0414 - val_accuracy: 0.6667 - 66ms/epoch - 33ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0412 - val_accuracy: 0.6667 - 77ms/epoch - 39ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.6667 - 74ms/epoch - 37ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.6667 - 69ms/epoch - 35ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.6667 - 76ms/epoch - 38ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.6667 - 70ms/epoch - 35ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.6667 - 76ms/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model3.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64117764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 2.2943 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2943434715270996, 0.5]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "965b2d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbcc825",
   "metadata": {},
   "source": [
    "#### Model with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5c33a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                16384     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,530\n",
      "Trainable params: 18,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(64, activation='relu',input_dim=X_train.shape[1]))\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(Dense(2, activation='sigmoid')) #output layer\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e9cb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 - 2s - loss: 0.7008 - accuracy: 0.2917 - val_loss: 0.6823 - val_accuracy: 0.5000 - 2s/epoch - 928ms/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 0.6889 - accuracy: 0.5833 - val_loss: 0.6837 - val_accuracy: 0.5000 - 60ms/epoch - 30ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 0.6793 - accuracy: 0.7083 - val_loss: 0.6844 - val_accuracy: 0.5000 - 57ms/epoch - 28ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 0.6709 - accuracy: 0.7917 - val_loss: 0.6847 - val_accuracy: 0.5000 - 55ms/epoch - 28ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 0.6623 - accuracy: 0.8333 - val_loss: 0.6848 - val_accuracy: 0.5000 - 65ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 0.6537 - accuracy: 0.8333 - val_loss: 0.6843 - val_accuracy: 0.5000 - 56ms/epoch - 28ms/step\n",
      "Epoch 7/100\n",
      "2/2 - 0s - loss: 0.6456 - accuracy: 0.9167 - val_loss: 0.6839 - val_accuracy: 0.5000 - 57ms/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "2/2 - 0s - loss: 0.6377 - accuracy: 0.9167 - val_loss: 0.6833 - val_accuracy: 0.6667 - 57ms/epoch - 28ms/step\n",
      "Epoch 9/100\n",
      "2/2 - 0s - loss: 0.6293 - accuracy: 0.9167 - val_loss: 0.6826 - val_accuracy: 0.6667 - 60ms/epoch - 30ms/step\n",
      "Epoch 10/100\n",
      "2/2 - 0s - loss: 0.6201 - accuracy: 0.9167 - val_loss: 0.6817 - val_accuracy: 0.6667 - 57ms/epoch - 29ms/step\n",
      "Epoch 11/100\n",
      "2/2 - 0s - loss: 0.6111 - accuracy: 0.9167 - val_loss: 0.6806 - val_accuracy: 0.6667 - 52ms/epoch - 26ms/step\n",
      "Epoch 12/100\n",
      "2/2 - 0s - loss: 0.6014 - accuracy: 0.9167 - val_loss: 0.6797 - val_accuracy: 0.6667 - 60ms/epoch - 30ms/step\n",
      "Epoch 13/100\n",
      "2/2 - 0s - loss: 0.5913 - accuracy: 0.9167 - val_loss: 0.6784 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
      "Epoch 14/100\n",
      "2/2 - 0s - loss: 0.5805 - accuracy: 0.9167 - val_loss: 0.6771 - val_accuracy: 0.6667 - 55ms/epoch - 27ms/step\n",
      "Epoch 15/100\n",
      "2/2 - 0s - loss: 0.5693 - accuracy: 0.9167 - val_loss: 0.6760 - val_accuracy: 0.6667 - 61ms/epoch - 30ms/step\n",
      "Epoch 16/100\n",
      "2/2 - 0s - loss: 0.5571 - accuracy: 0.9167 - val_loss: 0.6749 - val_accuracy: 0.6667 - 56ms/epoch - 28ms/step\n",
      "Epoch 17/100\n",
      "2/2 - 0s - loss: 0.5450 - accuracy: 0.9167 - val_loss: 0.6734 - val_accuracy: 0.6667 - 52ms/epoch - 26ms/step\n",
      "Epoch 18/100\n",
      "2/2 - 0s - loss: 0.5312 - accuracy: 0.9583 - val_loss: 0.6719 - val_accuracy: 0.6667 - 58ms/epoch - 29ms/step\n",
      "Epoch 19/100\n",
      "2/2 - 0s - loss: 0.5169 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.6667 - 57ms/epoch - 29ms/step\n",
      "Epoch 20/100\n",
      "2/2 - 0s - loss: 0.5017 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.6667 - 53ms/epoch - 26ms/step\n",
      "Epoch 21/100\n",
      "2/2 - 0s - loss: 0.4861 - accuracy: 1.0000 - val_loss: 0.6664 - val_accuracy: 0.6667 - 64ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "2/2 - 0s - loss: 0.4684 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.6667 - 56ms/epoch - 28ms/step\n",
      "Epoch 23/100\n",
      "2/2 - 0s - loss: 0.4506 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.6667 - 55ms/epoch - 28ms/step\n",
      "Epoch 24/100\n",
      "2/2 - 0s - loss: 0.4315 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.6667 - 57ms/epoch - 28ms/step\n",
      "Epoch 25/100\n",
      "2/2 - 0s - loss: 0.4120 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.6667 - 57ms/epoch - 28ms/step\n",
      "Epoch 26/100\n",
      "2/2 - 0s - loss: 0.3906 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
      "Epoch 27/100\n",
      "2/2 - 0s - loss: 0.3691 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
      "Epoch 28/100\n",
      "2/2 - 0s - loss: 0.3469 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.6667 - 57ms/epoch - 29ms/step\n",
      "Epoch 29/100\n",
      "2/2 - 0s - loss: 0.3251 - accuracy: 1.0000 - val_loss: 0.6463 - val_accuracy: 0.6667 - 55ms/epoch - 28ms/step\n",
      "Epoch 30/100\n",
      "2/2 - 0s - loss: 0.3024 - accuracy: 1.0000 - val_loss: 0.6430 - val_accuracy: 0.6667 - 59ms/epoch - 30ms/step\n",
      "Epoch 31/100\n",
      "2/2 - 0s - loss: 0.2796 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.6667 - 61ms/epoch - 30ms/step\n",
      "Epoch 32/100\n",
      "2/2 - 0s - loss: 0.2568 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.6667 - 56ms/epoch - 28ms/step\n",
      "Epoch 33/100\n",
      "2/2 - 0s - loss: 0.2350 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.6667 - 52ms/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "2/2 - 0s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 35/100\n",
      "2/2 - 0s - loss: 0.1938 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
      "Epoch 36/100\n",
      "2/2 - 0s - loss: 0.1750 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
      "Epoch 37/100\n",
      "2/2 - 0s - loss: 0.1568 - accuracy: 1.0000 - val_loss: 0.6153 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 38/100\n",
      "2/2 - 0s - loss: 0.1409 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.8333 - 53ms/epoch - 26ms/step\n",
      "Epoch 39/100\n",
      "2/2 - 0s - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
      "Epoch 40/100\n",
      "2/2 - 0s - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 41/100\n",
      "2/2 - 0s - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 42/100\n",
      "2/2 - 0s - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 43/100\n",
      "2/2 - 0s - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 44/100\n",
      "2/2 - 0s - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 45/100\n",
      "2/2 - 0s - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
      "Epoch 46/100\n",
      "2/2 - 0s - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8333 - 52ms/epoch - 26ms/step\n",
      "Epoch 47/100\n",
      "2/2 - 0s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 48/100\n",
      "2/2 - 0s - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 49/100\n",
      "2/2 - 0s - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "2/2 - 0s - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 51/100\n",
      "2/2 - 0s - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.8333 - 53ms/epoch - 27ms/step\n",
      "Epoch 52/100\n",
      "2/2 - 0s - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
      "Epoch 53/100\n",
      "2/2 - 0s - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 54/100\n",
      "2/2 - 0s - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8333 - 53ms/epoch - 26ms/step\n",
      "Epoch 55/100\n",
      "2/2 - 0s - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
      "Epoch 56/100\n",
      "2/2 - 0s - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
      "Epoch 57/100\n",
      "2/2 - 0s - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8333 - 59ms/epoch - 30ms/step\n",
      "Epoch 58/100\n",
      "2/2 - 0s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.8333 - 62ms/epoch - 31ms/step\n",
      "Epoch 59/100\n",
      "2/2 - 0s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8333 - 57ms/epoch - 29ms/step\n",
      "Epoch 60/100\n",
      "2/2 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 61/100\n",
      "2/2 - 0s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "2/2 - 0s - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 63/100\n",
      "2/2 - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.8333 - 49ms/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "2/2 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "2/2 - 0s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.8333 - 50ms/epoch - 25ms/step\n",
      "Epoch 66/100\n",
      "2/2 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
      "Epoch 67/100\n",
      "2/2 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.8333 - 64ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "2/2 - 0s - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 69/100\n",
      "2/2 - 0s - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8333 - 51ms/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "2/2 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 71/100\n",
      "2/2 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 72/100\n",
      "2/2 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
      "Epoch 73/100\n",
      "2/2 - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8333 - 51ms/epoch - 26ms/step\n",
      "Epoch 74/100\n",
      "2/2 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8333 - 52ms/epoch - 26ms/step\n",
      "Epoch 75/100\n",
      "2/2 - 0s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8333 - 61ms/epoch - 30ms/step\n",
      "Epoch 76/100\n",
      "2/2 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 77/100\n",
      "2/2 - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8333 - 49ms/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "2/2 - 0s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 79/100\n",
      "2/2 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 80/100\n",
      "2/2 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 81/100\n",
      "2/2 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n",
      "Epoch 82/100\n",
      "2/2 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.8333 - 52ms/epoch - 26ms/step\n",
      "Epoch 83/100\n",
      "2/2 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 84/100\n",
      "2/2 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.8333 - 60ms/epoch - 30ms/step\n",
      "Epoch 85/100\n",
      "2/2 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8333 - 55ms/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "2/2 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8333 - 54ms/epoch - 27ms/step\n",
      "Epoch 87/100\n",
      "2/2 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.8333 - 58ms/epoch - 29ms/step\n",
      "Epoch 88/100\n",
      "2/2 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.8333 - 49ms/epoch - 24ms/step\n",
      "Epoch 89/100\n",
      "2/2 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.8333 - 53ms/epoch - 26ms/step\n",
      "Epoch 90/100\n",
      "2/2 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.8333 - 48ms/epoch - 24ms/step\n",
      "Epoch 91/100\n",
      "2/2 - 0s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.8333 - 52ms/epoch - 26ms/step\n",
      "Epoch 92/100\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 93/100\n",
      "2/2 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.8333 - 53ms/epoch - 26ms/step\n",
      "Epoch 94/100\n",
      "2/2 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 95/100\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.8333 - 57ms/epoch - 28ms/step\n",
      "Epoch 96/100\n",
      "2/2 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.8333 - 55ms/epoch - 28ms/step\n",
      "Epoch 97/100\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 98/100\n",
      "2/2 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.8333 - 51ms/epoch - 25ms/step\n",
      "Epoch 99/100\n",
      "2/2 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.8333 - 56ms/epoch - 28ms/step\n",
      "Epoch 100/100\n",
      "2/2 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.8333 - 59ms/epoch - 29ms/step\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model4.fit(X_train,y_train,epochs=100,verbose=2,validation_split=0.2,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6301f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1434 - accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1434142589569092, 0.30000001192092896]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7150a552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
